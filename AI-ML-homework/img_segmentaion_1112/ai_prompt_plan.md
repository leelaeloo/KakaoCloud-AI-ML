# AI 프롬프트 기반 이미지 분할 도구

> Prompt-SAM Fusion : Text-Guided Semantic Segmentation System

---

## 1️⃣ 프로젝트 개요

프로젝트명: Prompt-SAM Fusion
핵심 목표:
사용자가 텍스트 프롬프트(명령어) 로 원하는 객체를 지정하면,

AI가 이미지 속 해당 대상을 자동으로 탐지하고 정밀하게 세그멘테이션하는 언어 + 시각 융합 AI 도구를 개발한다.

한줄 요약:

> “강아지만 분리해줘” 라고 입력하면 AI가 이미지 속 강아지만 정확히 잘라내는 텍스트 기반 세그멘테이션 시스템

---

## 2️⃣ 문제 정의

| 구분              | 내용                                                                                                 |
| ----------------- | ---------------------------------------------------------------------------------------------------- |
| **기존 문제점**   | 일반 세그멘테이션은 ‘사람이 직접 좌표나 박스를 지정’해야 객체를 분리할 수 있다.                      |
| **한계점**        | SAM 모델은 강력하지만 “어떤 객체를 찾을지”를 사람이 수동으로 지정해야 함.                            |
| **필요성**        | 언어로 객체를 설명하면 AI가 자동으로 해석 및 세그멘테이션을 수행하는 자연스러운 인터페이스 필요.     |
| **프로젝트 목표** | CLIP (텍스트–이미지 임베딩) + SAM (픽셀 세그멘테이션) 결합으로, 프롬프트 기반 객체 분할 시스템 개발. |

---

## 3️⃣ 핵심 아이디어

> CLIP 을 통해 “텍스트 의미 공간”과 “이미지 특징 공간”을 연결하고, SAM 이 그 결과를 픽셀 단위 마스크로 정밀 분할한다.

🔍 처리 순서

1. 사용자 프롬프트 입력 (예: “red car”, “person with umbrella”)

2. CLIP 텍스트 임베딩 생성

3. 이미지 특징 벡터 (CLIP image encoder 또는 SAM backbone) 계산

4. 유사도 ( cosine similarity ) 기반으로 해당 클래스 영역 추출

5. SAM 에 해당 위치 정보 전달 → 정밀 마스크 생성

6. 시각화 및 결과 저장

---

## 4️⃣ 기대 효과

| 구분                            | 내용                                                 |
| ------------------------------- | ---------------------------------------------------- |
| 🧠 **자연어 기반 세그멘테이션** | “무엇을 분리할지”를 텍스트로 설명 → 즉시 객체 추출   |
| ⚡ **비전 + 언어 융합 AI**      | CLIP + SAM 결합으로 멀티모달 모델 활용               |
| 🎯 **정확도 향상**              | CLIP 의 의미 이해 + SAM 의 경계 정밀도 결합          |
| 👥 **직관적 사용성**            | 클릭 대신 텍스트로 명령하는 UI 제공                  |
| 📦 **응용 확장성**              | 이미지 검색, 편집, 자율주행, 의료, AR 등에 활용 가능 |

---

## 5️⃣ 시스템 구성도

```pgsql

⏹️ Prompt-SAM Fusion System
│
├─ ① Text Prompt Input Layer
│    └─ 텍스트 입력 및 자연어 전처리
│
├─ ② CLIP Embedding Layer
│    ├─ 텍스트 및 이미지 임베딩 벡터 생성
│    └─ 유사도 계산 후 객체 영역 추정
│
├─ ③ SAM Segmentation Layer
│    ├─ 해당 좌표 또는 박스 프롬프트 전달
│    └─ 픽셀 단위 마스크 생성
│
└─ ④ Visualization & Export Layer
     ├─ OpenCV / PIL 기반 시각화
     └─ 마스크 결과 저장 (PNG / JSON)

```

---

## 6️⃣ 핵심 기술 구성

| 구성 요소             | 기술 및 라이브러리                             |
| --------------------- | ---------------------------------------------- |
| **텍스트 임베딩**     | OpenAI CLIP / Sentence-Transformer (BERT 기반) |
| **이미지 인코더**     | CLIP Visual Encoder / SAM ViT-B 백본           |
| **세그멘테이션 엔진** | Segment Anything (SAM) Predictor               |
| **시각화**            | OpenCV, PIL, Matplotlib                        |
| **GUI (선택)**        | Tkinter 또는 Gradio 웹 UI                      |
| **추가 모듈**         | NumPy, PyTorch, Transformers                   |

---

## 7️⃣ 예시 동작 시나리오

### 1️⃣ 사용자 입력:

> “파란색 자전거를 분리해줘”

### 2️⃣ 시스템 처리:

- CLIP 이 “blue bicycle” 텍스트 벡터 생성

- 이미지 내 각 객체 특징 벡터와 유사도 비교

- 유사도가 가장 높은 위치 좌표 추출

- SAM Predictor에 박스/포인트 프롬프트로 전달

### 3️⃣ 출력 결과:

- 자전거 영역 정밀 마스크 생성

- 반투명 오버레이로 시각화

- 결과 이미지 및 마스크 파일 저장

---

## 8️⃣ 기능 목록

| 기능                 | 설명                                                |
| -------------------- | --------------------------------------------------- |
| **텍스트 입력 UI**   | 사용자가 자연어로 객체 지시                         |
| **CLIP 유사도 매칭** | 텍스트–이미지 간 유사도 매트릭스 계산               |
| **SAM 연동**         | 선택된 좌표 → 세그멘테이션 결과 생성                |
| **마스크 시각화**    | PIL 및 Matplotlib 기반 반투명 표시                  |
| **결과 저장**        | PNG / JSON 포맷 저장 (클래스명 포함)                |
| **멀티 객체 지원**   | 여러 프롬프트 순차 입력 지원 (예: “사람 및 자동차”) |

---

## 9️⃣ 평가 및 성과 지표 (10점 체계)

| 평가 항목               | 목표              | 설명                        |
| ----------------------- | ----------------- | --------------------------- |
| **텍스트–시각 정확도**  | ≥ 0.85 Cosine Sim | CLIP 임베딩 정확성          |
| **세그멘테이션 정밀도** | IoU ≥ 0.9         | SAM 마스크 정확도           |
| **응답 시간**           | ≤ 1.0 초          | 프롬프트 → 마스크 생성 속도 |
| **프롬프트 유연성**     | 10점              | 자연어 변형에도 안정적 결과 |
| **시각화 품질**         | 9점 이상          | 결과 해석 및 시각적 완성도  |
| **확장성**              | 9점               | 멀티객체/비디오 지원 가능성 |

---

## 🔟 프로젝트 일정 (12주 계획)

| 주차      | 주요 내용                                      |
| --------- | ---------------------------------------------- |
| 1–2주차   | 환경 구축, CLIP 및 SAM 모델 세팅               |
| 3–4주차   | 텍스트 입력 → CLIP 유사도 추정 파이프라인 구현 |
| 5–6주차   | SAM 결합 및 좌표 자동 추출 로직 개발           |
| 7–8주차   | 시각화 및 마스크 결과 저장 기능 완성           |
| 9–10주차  | GUI / Gradio 웹 버전 추가                      |
| 11–12주차 | 성능 평가 및 보고서 작성 (10점 체계 완성)      |

---

## 1️⃣1️⃣ 응용 분야

| 분야             | 적용 사례                        |
| ---------------- | -------------------------------- |
| **이미지 검색**  | “빨간 자동차가 있는 이미지 찾기” |
| **AI 편집툴**    | “강아지만 남기고 배경 지워줘”    |
| **자율주행**     | “보행자 및 차선만 감지”          |
| **의료 영상**    | “종양 영역만 표시해줘”           |
| **AR/VR 콘텐츠** | 음성 명령 기반 객체 분리 및 배치 |
| **교육 AI**      | 자연어 → 시각 결과 시연 플랫폼   |

---

## 1️⃣2️⃣ 차별화 포인트

- 💬 텍스트 명령 기반 세그멘테이션 → 완전 비전 UI 자율화

- 🔗 CLIP + SAM 융합 시스템 → 의미 이해 + 픽셀 정밀 동시 달성

- 🧠 멀티모달 확장성 → LLaVA / BLIP / GPT-Vision 통합 가능

- ⚡ 실시간 응답성 → 인터랙티브 편집 및 시연 용이

- 🧩 범용성 → 의료, 산업, 예술 등 다양한 분야 적용 가능

---

## 1️⃣3️⃣ 결론

Prompt-SAM Fusion 은
기존의 “좌표 기반 세그멘테이션”을 완전히 대체하는
텍스트 기반 비전 인터페이스 를 제안합니다.

- 자연어 → 시각적 행동 → 픽셀 단위 결과 라는 새로운 패러다임

- CLIP 과 SAM 의 결합으로 “이해력 + 정밀도” 를 모두 획득

- 차세대 AI 편집, 검색, 로봇 비전 기술의 핵심 요소로 성장 가능

> “텍스트로 이미지를 제어하는 AI, Prompt-SAM Fusion.” 사람이 아닌 ‘언어’가 AI 시각을 조종하는 새로운 세대의 도구다.

---
